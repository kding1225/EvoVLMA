[
     {
          "algorithm": "The new algorithm selects feature channels by maximizing class-specific discriminative power, minimizing cross-class feature overlap, incorporating feature variance across samples, and introducing a class-specific feature interaction score based on pairwise feature correlations.",
          "code": "import torch\n\ndef feat_selection(clip_weights, train_feats, w0, w1, topk):\n    cate_num, samp_num, feat_dim = train_feats.shape\n    \n    # Compute class-specific feature relevance based on CLIP weights\n    class_relevance = torch.einsum('cd,cnd->d', clip_weights, train_feats) / (cate_num * samp_num)\n    \n    # Compute global feature consistency\n    global_consistency = torch.mean(train_feats, dim=(0, 1))\n    \n    # Compute class-specific discriminative power\n    class_means = train_feats.mean(dim=1)\n    discriminative_power = torch.sum((class_means - global_consistency) ** 2, dim=0)\n    \n    # Compute cross-class feature overlap\n    cross_overlap = torch.sum(class_means ** 2, dim=0)\n    \n    # Compute feature variance across samples\n    feature_variance = torch.var(train_feats, dim=(0, 1))\n    \n    # Compute class-specific feature interaction score\n    class_feats = train_feats.permute(1, 0, 2)  # (k, c, d)\n    pairwise_corr = torch.einsum('kcd,kcd->d', class_feats, class_feats) / (cate_num * samp_num)\n    \n    # Combine criteria with dynamic feature saliency\n    criterion = w0 * class_relevance * global_consistency * discriminative_power - w1 * cross_overlap + feature_variance + pairwise_corr\n    \n    # Select topk features\n    _, indices = torch.topk(criterion, k=topk)\n    \n    return indices",
          "objective": 39.79105,
          "other_inf": null
     },
     {
          "algorithm": "The new algorithm selects feature channels by maximizing class-specific discriminative power, minimizing cross-class feature overlap, and incorporating a dynamic feature saliency score based on the interaction between class-specific feature relevance, global feature consistency, and feature variance across samples.",
          "code": "import torch\n\ndef feat_selection(clip_weights, train_feats, w0, w1, topk):\n    cate_num, samp_num, feat_dim = train_feats.shape\n    \n    # Compute class-specific feature relevance based on CLIP weights\n    class_relevance = torch.einsum('cd,cnd->d', clip_weights, train_feats) / (cate_num * samp_num)\n    \n    # Compute global feature consistency\n    global_consistency = torch.mean(train_feats, dim=(0, 1))\n    \n    # Compute class-specific discriminative power\n    class_means = train_feats.mean(dim=1)\n    discriminative_power = torch.sum((class_means - global_consistency) ** 2, dim=0)\n    \n    # Compute cross-class feature overlap\n    cross_overlap = torch.sum(class_means ** 2, dim=0)\n    \n    # Compute feature variance across samples\n    feature_variance = torch.var(train_feats, dim=(0, 1))\n    \n    # Combine criteria with dynamic feature saliency\n    criterion = w0 * class_relevance * global_consistency * discriminative_power - w1 * cross_overlap + feature_variance\n    \n    # Select topk features\n    _, indices = torch.topk(criterion, k=topk)\n    \n    return indices",
          "objective": 39.8094,
          "other_inf": null
     },
     {
          "algorithm": "The new algorithm selects feature channels by maximizing class-specific discriminative power, minimizing cross-class feature overlap, and incorporating a dynamic feature saliency score based on the interaction between class-specific feature relevance, global feature consistency, feature variance across samples, and class-specific feature sparsity.",
          "code": "import torch\n\ndef feat_selection(clip_weights, train_feats, w0, w1, topk):\n    cate_num, samp_num, feat_dim = train_feats.shape\n    \n    # Compute class-specific feature relevance based on CLIP weights\n    class_relevance = torch.einsum('cd,cnd->d', clip_weights, train_feats) / (cate_num * samp_num)\n    \n    # Compute global feature consistency\n    global_consistency = torch.mean(train_feats, dim=(0, 1))\n    \n    # Compute class-specific discriminative power\n    class_means = train_feats.mean(dim=1)\n    discriminative_power = torch.sum((class_means - global_consistency) ** 2, dim=0)\n    \n    # Compute cross-class feature overlap\n    cross_overlap = torch.sum(class_means ** 2, dim=0)\n    \n    # Compute feature variance across samples\n    feature_variance = torch.var(train_feats, dim=(0, 1))\n    \n    # Compute class-specific feature sparsity\n    feature_sparsity = torch.sum(torch.abs(train_feats), dim=(0, 1)) / (cate_num * samp_num)\n    \n    # Combine criteria with dynamic feature saliency\n    criterion = w0 * class_relevance * global_consistency * discriminative_power - w1 * cross_overlap + feature_variance - feature_sparsity\n    \n    # Select topk features\n    _, indices = torch.topk(criterion, k=topk)\n    \n    return indices",
          "objective": 40.07046,
          "other_inf": null
     },
     {
          "algorithm": "The new algorithm selects feature channels by maximizing the class-specific discriminative power of features, minimizing the cross-class feature overlap, and incorporating a dynamic feature saliency score based on the interaction between class-specific feature relevance and global feature consistency.",
          "code": "import torch\n\ndef feat_selection(clip_weights, train_feats, w0, w1, topk):\n    cate_num, samp_num, feat_dim = train_feats.shape\n    \n    # Compute class-specific feature relevance based on CLIP weights\n    class_relevance = torch.einsum('cd,cnd->d', clip_weights, train_feats) / (cate_num * samp_num)\n    \n    # Compute global feature consistency\n    global_consistency = torch.mean(train_feats, dim=(0, 1))\n    \n    # Compute class-specific discriminative power\n    class_means = train_feats.mean(dim=1)\n    discriminative_power = torch.sum((class_means - global_consistency) ** 2, dim=0)\n    \n    # Compute cross-class feature overlap\n    cross_overlap = torch.sum(class_means ** 2, dim=0)\n    \n    # Combine criteria with dynamic feature saliency\n    criterion = w0 * class_relevance * global_consistency * discriminative_power - w1 * cross_overlap\n    \n    # Select topk features\n    _, indices = torch.topk(criterion, k=topk)\n    \n    return indices",
          "objective": 40.07515,
          "other_inf": null
     },
     {
          "algorithm": "The new algorithm selects feature channels by maximizing the alignment between visual and textual features, minimizing the feature redundancy across classes, and incorporating class-specific feature importance based on the divergence of visual features from the global mean.",
          "code": "import torch\n\ndef feat_selection(clip_weights, train_feats, w0, w1, topk):\n    cate_num, samp_num, feat_dim = train_feats.shape\n    \n    # Compute class-wise mean of visual features\n    class_means = train_feats.mean(dim=1)  # Shape: (cate_num, feat_dim)\n    \n    # Compute alignment between visual and textual features\n    alignment = torch.sum(class_means * clip_weights, dim=0)  # Shape: (feat_dim)\n    \n    # Compute global mean of visual features\n    global_mean = class_means.mean(dim=0)  # Shape: (feat_dim)\n    \n    # Compute class-specific feature importance based on divergence from global mean\n    divergence = torch.sum((class_means - global_mean) ** 2, dim=0)  # Shape: (feat_dim)\n    \n    # Compute redundancy across classes\n    redundancy = torch.sum(class_means ** 2, dim=0)  # Shape: (feat_dim)\n    \n    # Combine criteria with weights\n    criterion = w0 * alignment * divergence - w1 * redundancy\n    \n    # Select topk features\n    _, indices = torch.topk(criterion, k=topk)\n    \n    return indices",
          "objective": 40.12081,
          "other_inf": null
     },
     {
          "algorithm": "The new algorithm selects feature channels by maximizing the inter-class cosine similarity between visual and textual features, minimizing the intra-class cosine similarity of visual features, and incorporating a dynamic feature importance score based on the interaction between class-specific importance and global feature activation.",
          "code": "import torch\n\ndef feat_selection(clip_weights, train_feats, w0, w1, topk):\n    cate_num, samp_num, feat_dim = train_feats.shape\n    \n    # Compute inter-class cosine similarity between visual and textual features\n    inter_sim = torch.einsum('cd,cnd->d', clip_weights, train_feats) / (cate_num * (cate_num - 1))\n    \n    # Compute intra-class cosine similarity of visual features\n    intra_sim = torch.einsum('cnd,cnd->d', train_feats, train_feats) / (cate_num * samp_num * samp_num)\n    \n    # Compute class-specific importance based on the interaction between CLIP weights and train features\n    class_importance = torch.einsum('cd,cnd->d', clip_weights, train_feats) / (cate_num * samp_num)\n    \n    # Compute global feature activation\n    global_activation = torch.mean(train_feats, dim=(0, 1))\n    \n    # Combine criteria with dynamic feature importance\n    criterion = w0 * inter_sim * class_importance * global_activation - w1 * intra_sim\n    \n    # Select topk features\n    _, indices = torch.topk(criterion, k=topk)\n    return indices",
          "objective": 40.13521,
          "other_inf": null
     },
     {
          "algorithm": "The new algorithm selects feature channels by maximizing the inter-class cosine similarity between visual and textual features while minimizing the intra-class cosine similarity of the visual features, weighted by the class-specific importance derived from the CLIP weights, and incorporating a feature diversity term to ensure a balanced selection of features across different classes.",
          "code": "import torch\n\ndef feat_selection(clip_weights, train_feats, w0, w1, topk):\n    cate_num, samp_num, feat_dim = train_feats.shape\n    \n    # Compute inter-class cosine similarity between visual and textual features\n    inter_sim = torch.einsum('cd,cld->d', clip_weights, train_feats) / (cate_num * (cate_num - 1))\n    \n    # Compute intra-class cosine similarity of visual features\n    intra_sim = torch.einsum('cld,cmd->d', train_feats, train_feats) / (cate_num * samp_num * samp_num)\n    \n    # Compute feature diversity term\n    class_importance = torch.sum(clip_weights, dim=0)\n    feature_diversity = torch.std(clip_weights, dim=0)\n    \n    # Combine criteria with class-specific importance and feature diversity\n    criterion = w0 * inter_sim * class_importance - w1 * intra_sim + (1 - w0 - w1) * feature_diversity\n    \n    # Select topk features\n    _, indices = torch.topk(criterion, k=topk)\n    return indices",
          "objective": 40.15617,
          "other_inf": null
     },
     {
          "algorithm": "The new algorithm selects feature channels by maximizing the class-specific feature relevance derived from CLIP weights, minimizing the feature overlap across classes, and incorporating a feature uniqueness term that prioritizes features with distinct contributions to different classes.",
          "code": "import torch\n\ndef feat_selection(clip_weights, train_feats, w0, w1, topk):\n    cate_num, samp_num, feat_dim = train_feats.shape\n    \n    # Compute class-specific feature relevance based on CLIP weights\n    feature_relevance = torch.sum(clip_weights.abs(), dim=0)  # Shape: (feat_dim)\n    \n    # Compute feature overlap across classes\n    class_means = train_feats.mean(dim=1)  # Shape: (cate_num, feat_dim)\n    overlap = torch.sum(class_means.abs(), dim=0)  # Shape: (feat_dim)\n    \n    # Compute feature uniqueness across classes\n    feature_uniqueness = 1 / (torch.sum(clip_weights ** 2, dim=0) + 1e-8)  # Shape: (feat_dim)\n    \n    # Combine criteria with weights\n    criterion = w0 * feature_relevance - w1 * overlap + (1 - w0 - w1) * feature_uniqueness\n    \n    # Select topk features\n    _, indices = torch.topk(criterion, k=topk)\n    \n    return indices",
          "objective": 40.26875,
          "other_inf": null
     },
     {
          "algorithm": "The new algorithm selects feature channels by maximizing class-specific feature saliency derived from the interaction between CLIP weights and train features, minimizing feature redundancy across classes, and incorporating a class-specific feature stability term based on feature consistency across samples.",
          "code": "import torch\n\ndef feat_selection(clip_weights, train_feats, w0, w1, topk):\n    cate_num, samp_num, feat_dim = train_feats.shape\n    \n    # Compute class-specific feature saliency\n    class_saliency = torch.einsum('cd,cnd->d', clip_weights, train_feats) / (cate_num * samp_num)\n    \n    # Compute feature redundancy across classes\n    class_means = train_feats.mean(dim=1)\n    feature_redundancy = torch.sum(class_means ** 2, dim=0)\n    \n    # Compute class-specific feature stability\n    feature_stability = torch.var(train_feats, dim=(0, 1))\n    \n    # Combine criteria with dynamic feature saliency\n    criterion = w0 * class_saliency - w1 * feature_redundancy + (1 - w0 - w1) * feature_stability\n    \n    # Select topk features\n    _, indices = torch.topk(criterion, k=topk)\n    \n    return indices",
          "objective": 40.27839,
          "other_inf": null
     },
     {
          "algorithm": "The new algorithm selects feature channels by maximizing class-specific feature relevance, minimizing feature overlap across classes, and incorporating a feature diversity term that prioritizes features with high variance across classes.",
          "code": "import torch\n\ndef feat_selection(clip_weights, train_feats, w0, w1, topk):\n    cate_num, samp_num, feat_dim = train_feats.shape\n    \n    # Compute class-specific feature relevance based on CLIP weights\n    feature_relevance = torch.sum(clip_weights.abs(), dim=0)  # Shape: (feat_dim)\n    \n    # Compute feature overlap across classes\n    class_means = train_feats.mean(dim=1)  # Shape: (cate_num, feat_dim)\n    overlap = torch.sum(class_means.abs(), dim=0)  # Shape: (feat_dim)\n    \n    # Compute feature diversity across classes\n    feature_variance = torch.var(train_feats, dim=(0, 1))  # Shape: (feat_dim)\n    \n    # Combine criteria with weights\n    criterion = w0 * feature_relevance - w1 * overlap + (1 - w0 - w1) * feature_variance\n    \n    # Select topk features\n    _, indices = torch.topk(criterion, k=topk)\n    \n    return indices",
          "objective": 40.28075,
          "other_inf": null
     }
]