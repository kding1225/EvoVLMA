[
     {
          "algorithm": "The new algorithm selects feature channels by maximizing a weighted combination of the mutual information between visual and textual features, the discriminative power of visual features across classes, the sparsity of the selected channels, the correlation between visual and textual features, and the entropy of the visual features, while incorporating the variance of category textual features as a weighting factor.",
          "code": "import torch\n\ndef feat_selection(clip_weights, train_feats, w0, w1, topk):\n    cate_num, samp_num, feat_dim = train_feats.shape\n    \n    # Compute mutual information between visual and textual features\n    visual_mean = train_feats.mean(dim=1)  # (c, d)\n    mi = torch.sum(visual_mean * clip_weights, dim=0)  # (d,)\n    \n    # Compute discriminative power of visual features across classes\n    inter_class_div = torch.var(visual_mean, dim=0)  # (d,)\n    \n    # Compute sparsity of the selected channels\n    sparsity = torch.sum(torch.abs(visual_mean), dim=0)  # (d,)\n    \n    # Compute correlation between visual and textual features\n    correlation = torch.sum(visual_mean * clip_weights, dim=0)  # (d,)\n    \n    # Compute variance of category textual features\n    text_var = torch.var(clip_weights, dim=0)  # (d,)\n    \n    # Compute entropy of visual features\n    visual_prob = torch.softmax(visual_mean, dim=0)\n    entropy = -torch.sum(visual_prob * torch.log(visual_prob + 1e-10), dim=0)  # (d,)\n    \n    # Combine criteria\n    criterion = w0 * mi + (1 - w0) * inter_class_div - w1 * sparsity + (1 - w1) * text_var + correlation + entropy\n    \n    # Select topk features\n    _, indices = torch.topk(criterion, k=topk)\n    return indices",
          "objective": 39.91889,
          "other_inf": null
     },
     {
          "algorithm": "The new algorithm selects feature channels by maximizing the weighted sum of the mutual information between visual and textual features, the discriminative power of visual features across classes, the sparsity of the selected channels, and the correlation between visual and textual features, while incorporating the variance of category textual features as a weighting factor.",
          "code": "import torch\n\ndef feat_selection(clip_weights, train_feats, w0, w1, topk):\n    cate_num, samp_num, feat_dim = train_feats.shape\n    \n    # Compute mutual information between visual and textual features\n    visual_mean = train_feats.mean(dim=1)  # (c, d)\n    mi = torch.sum(visual_mean * clip_weights, dim=0)  # (d,)\n    \n    # Compute discriminative power of visual features across classes\n    inter_class_div = torch.var(visual_mean, dim=0)  # (d,)\n    \n    # Compute sparsity of the selected channels\n    sparsity = torch.sum(torch.abs(visual_mean), dim=0)  # (d,)\n    \n    # Compute correlation between visual and textual features\n    correlation = torch.sum(visual_mean * clip_weights, dim=0)  # (d,)\n    \n    # Compute variance of category textual features\n    text_var = torch.var(clip_weights, dim=0)  # (d,)\n    \n    # Combine criteria\n    criterion = w0 * mi + (1 - w0) * inter_class_div - w1 * sparsity + (1 - w1) * text_var + correlation\n    \n    # Select topk features\n    _, indices = torch.topk(criterion, k=topk)\n    return indices",
          "objective": 39.9748,
          "other_inf": null
     },
     {
          "algorithm": "The new algorithm selects feature channels by maximizing the weighted sum of the mutual information between visual and textual features, the discriminative power of visual features across classes, and the sparsity of the selected channels, while incorporating the variance of category textual features as a weighting factor.",
          "code": "import torch\n\ndef feat_selection(clip_weights, train_feats, w0, w1, topk):\n    cate_num, samp_num, feat_dim = train_feats.shape\n    \n    # Compute mutual information between visual and textual features\n    visual_mean = train_feats.mean(dim=1)  # (c, d)\n    mi = torch.sum(visual_mean * clip_weights, dim=0)  # (d,)\n    \n    # Compute discriminative power of visual features across classes\n    inter_class_div = torch.var(visual_mean, dim=0)  # (d,)\n    \n    # Compute sparsity of the selected channels\n    sparsity = torch.sum(torch.abs(visual_mean), dim=0)  # (d,)\n    \n    # Compute variance of category textual features\n    text_var = torch.var(clip_weights, dim=0)  # (d,)\n    \n    # Combine criteria\n    criterion = w0 * mi + (1 - w0) * inter_class_div - w1 * sparsity + (1 - w1) * text_var\n    \n    # Select topk features\n    _, indices = torch.topk(criterion, k=topk)\n    return indices",
          "objective": 40.0735,
          "other_inf": null
     },
     {
          "algorithm": "The new algorithm selects feature channels by maximizing the correlation between visual features and textual features while minimizing the redundancy among selected channels, weighted by the variance of category textual features.",
          "code": "import torch\n\ndef feat_selection(clip_weights, train_feats, w0, w1, topk):\n    cate_num, samp_num, feat_dim = train_feats.shape\n    \n    # Compute correlation between visual and textual features\n    visual_mean = train_feats.mean(dim=1)  # (c, d)\n    corr = torch.matmul(visual_mean, clip_weights.T).diag()  # (c,)\n    corr = corr.mean(dim=0)  # (d,)\n    \n    # Compute redundancy among selected channels\n    redundancy = torch.matmul(visual_mean.T, visual_mean).diag()  # (d,)\n    \n    # Combine criteria\n    criterion = w0 * corr - w1 * redundancy + (1 - w0 - w1) * torch.var(clip_weights, dim=0)\n    \n    _, indices = torch.topk(criterion, k=topk)\n    return indices",
          "objective": 40.10795,
          "other_inf": null
     },
     {
          "algorithm": "The new algorithm selects feature channels by maximizing a weighted combination of the mutual information between visual and textual features, the discriminative power of visual features across classes, the sparsity of the selected channels, the correlation between visual and textual features, the entropy of the visual features, and the variance of category textual features, while incorporating the class-specific importance of features based on their alignment with class prototypes.",
          "code": "import torch\n\ndef feat_selection(clip_weights, train_feats, w0, w1, topk):\n    cate_num, samp_num, feat_dim = train_feats.shape\n    \n    # Compute class prototypes\n    class_prototypes = train_feats.mean(dim=1)  # (c, d)\n    \n    # Compute mutual information between visual and textual features\n    mi = torch.sum(class_prototypes * clip_weights, dim=0)  # (d,)\n    \n    # Compute discriminative power of visual features across classes\n    inter_class_div = torch.var(class_prototypes, dim=0)  # (d,)\n    \n    # Compute sparsity of the selected channels\n    sparsity = torch.sum(torch.abs(class_prototypes), dim=0)  # (d,)\n    \n    # Compute correlation between visual and textual features\n    correlation = torch.sum(class_prototypes * clip_weights, dim=0)  # (d,)\n    \n    # Compute variance of category textual features\n    text_var = torch.var(clip_weights, dim=0)  # (d,)\n    \n    # Compute entropy of visual features\n    visual_prob = torch.softmax(class_prototypes, dim=0)\n    entropy = -torch.sum(visual_prob * torch.log(visual_prob + 1e-10), dim=0)  # (d,)\n    \n    # Compute class-specific importance based on alignment with class prototypes\n    class_importance = torch.sum(class_prototypes * clip_weights, dim=1)  # (c,)\n    class_importance = torch.softmax(class_importance, dim=0)  # (c,)\n    class_specific_importance = torch.sum(class_prototypes * class_importance.unsqueeze(1), dim=0)  # (d,)\n    \n    # Combine criteria\n    criterion = w0 * mi + (1 - w0) * inter_class_div - w1 * sparsity + (1 - w1) * text_var + correlation + entropy + class_specific_importance\n    \n    # Select topk features\n    _, indices = torch.topk(criterion, k=topk)\n    return indices",
          "objective": 40.11332,
          "other_inf": null
     },
     {
          "algorithm": "The new algorithm selects feature channels by maximizing a weighted combination of the mutual information between visual and textual features, the discriminative power of visual features across classes, the sparsity of the selected channels, the correlation between visual and textual features, and the inter-class variance of visual features, while incorporating the intra-class variance of visual features as a weighting factor.",
          "code": "import torch\n\ndef feat_selection(clip_weights, train_feats, w0, w1, topk):\n    cate_num, samp_num, feat_dim = train_feats.shape\n    \n    # Compute mutual information between visual and textual features\n    visual_mean = train_feats.mean(dim=1)  # (c, d)\n    mi = torch.sum(visual_mean * clip_weights, dim=0)  # (d,)\n    \n    # Compute discriminative power of visual features across classes\n    inter_class_div = torch.var(visual_mean, dim=0)  # (d,)\n    \n    # Compute sparsity of the selected channels\n    sparsity = torch.sum(torch.abs(visual_mean), dim=0)  # (d,)\n    \n    # Compute correlation between visual and textual features\n    correlation = torch.sum(visual_mean * clip_weights, dim=0)  # (d,)\n    \n    # Compute intra-class variance of visual features\n    intra_class_var = torch.var(train_feats, dim=1).mean(dim=0)  # (d,)\n    \n    # Combine criteria\n    criterion = w0 * mi + (1 - w0) * inter_class_div - w1 * sparsity + (1 - w1) * intra_class_var + correlation\n    \n    # Select topk features\n    _, indices = torch.topk(criterion, k=topk)\n    return indices",
          "objective": 40.11918,
          "other_inf": null
     },
     {
          "algorithm": "The new algorithm selects feature channels by maximizing a weighted combination of the cosine similarity between visual and textual features, the inter-class variance of visual features, the sparsity of the selected channels, and the entropy of the textual feature distribution, while incorporating the L2 norm of the visual features as a weighting factor.",
          "code": "import torch\n\ndef feat_selection(clip_weights, train_feats, w0, w1, topk):\n    cate_num, samp_num, feat_dim = train_feats.shape\n    \n    # Compute cosine similarity between visual and textual features\n    visual_mean = train_feats.mean(dim=1)  # (c, d)\n    cosine_sim = torch.sum(visual_mean * clip_weights, dim=0)  # (d,)\n    \n    # Compute inter-class variance of visual features\n    inter_class_var = torch.var(visual_mean, dim=0)  # (d,)\n    \n    # Compute sparsity of the selected channels\n    sparsity = torch.sum(torch.abs(visual_mean), dim=0)  # (d,)\n    \n    # Compute entropy of the textual feature distribution\n    text_dist = torch.softmax(clip_weights, dim=0)\n    text_entropy = -torch.sum(text_dist * torch.log(text_dist + 1e-9), dim=0)  # (d,)\n    \n    # Compute L2 norm of the visual features\n    l2_norm = torch.norm(visual_mean, p=2, dim=0)  # (d,)\n    \n    # Combine criteria\n    criterion = w0 * cosine_sim + (1 - w0) * inter_class_var - w1 * sparsity + (1 - w1) * text_entropy + l2_norm\n    \n    # Select topk features\n    _, indices = torch.topk(criterion, k=topk)\n    return indices",
          "objective": 40.12025,
          "other_inf": null
     },
     {
          "algorithm": "The new algorithm selects feature channels by maximizing a combination of the cosine similarity between visual and textual features, the inter-class variance of visual features weighted by the variance of textual features, the sparsity of visual features, and the entropy of visual feature activations across classes.",
          "code": "import torch\n\ndef feat_selection(clip_weights, train_feats, w0, w1, topk):\n    cate_num, samp_num, feat_dim = train_feats.shape\n    \n    # Compute cosine similarity between visual and textual features\n    visual_mean = train_feats.mean(dim=1)  # (c, d)\n    cosine_sim = torch.sum(visual_mean * clip_weights, dim=0)  # (d,)\n    \n    # Compute inter-class variance of visual features\n    inter_class_var = torch.var(visual_mean, dim=0)  # (d,)\n    \n    # Compute variance of category textual features\n    text_var = torch.var(clip_weights, dim=0)  # (d,)\n    \n    # Compute sparsity of visual features\n    sparsity = torch.sum(torch.abs(visual_mean), dim=0)  # (d,)\n    \n    # Compute entropy of visual feature activations across classes\n    prob = torch.softmax(visual_mean, dim=0)  # (c, d)\n    entropy = -torch.sum(prob * torch.log(prob + 1e-8), dim=0)  # (d,)\n    \n    # Combine criteria\n    criterion = w0 * cosine_sim + (1 - w0) * inter_class_var * text_var - w1 * sparsity + (1 - w1) * entropy\n    \n    # Select topk features\n    _, indices = torch.topk(criterion, k=topk)\n    return indices",
          "objective": 40.13065,
          "other_inf": null
     },
     {
          "algorithm": "The new algorithm selects feature channels by maximizing a weighted combination of the mutual information between visual and textual features, the inter-class variance of visual features, the sparsity of the selected channels, the correlation between visual and textual features, and the entropy of the visual features, while incorporating the intra-class variance of visual features as a weighting factor.",
          "code": "import torch\n\ndef feat_selection(clip_weights, train_feats, w0, w1, topk):\n    cate_num, samp_num, feat_dim = train_feats.shape\n    \n    # Compute mutual information between visual and textual features\n    visual_mean = train_feats.mean(dim=1)  # (c, d)\n    mi = torch.sum(visual_mean * clip_weights, dim=0)  # (d,)\n    \n    # Compute inter-class variance of visual features\n    inter_class_var = torch.var(visual_mean, dim=0)  # (d,)\n    \n    # Compute sparsity of the selected channels\n    sparsity = torch.sum(torch.abs(visual_mean), dim=0)  # (d,)\n    \n    # Compute correlation between visual and textual features\n    correlation = torch.sum(visual_mean * clip_weights, dim=0)  # (d,)\n    \n    # Compute intra-class variance of visual features\n    intra_class_var = torch.var(train_feats, dim=1).mean(dim=0)  # (d,)\n    \n    # Compute entropy of visual features\n    visual_prob = torch.softmax(visual_mean, dim=0)\n    entropy = -torch.sum(visual_prob * torch.log(visual_prob + 1e-10), dim=0)  # (d,)\n    \n    # Combine criteria\n    criterion = w0 * mi + (1 - w0) * inter_class_var - w1 * sparsity + (1 - w1) * intra_class_var + correlation + entropy\n    \n    # Select topk features\n    _, indices = torch.topk(criterion, k=topk)\n    return indices",
          "objective": 40.14327,
          "other_inf": null
     },
     {
          "algorithm": "The new algorithm selects feature channels by maximizing a weighted combination of the mutual information between visual and textual features, the discriminative power of visual features across classes, the sparsity of the selected channels, the correlation between visual and textual features, the entropy of the visual features, and the variance of category textual features, while incorporating the class-wise feature consistency as an additional weighting factor.",
          "code": "import torch\n\ndef feat_selection(clip_weights, train_feats, w0, w1, topk):\n    cate_num, samp_num, feat_dim = train_feats.shape\n    \n    # Compute mutual information between visual and textual features\n    visual_mean = train_feats.mean(dim=1)  # (c, d)\n    mi = torch.sum(visual_mean * clip_weights, dim=0)  # (d,)\n    \n    # Compute discriminative power of visual features across classes\n    inter_class_div = torch.var(visual_mean, dim=0)  # (d,)\n    \n    # Compute sparsity of the selected channels\n    sparsity = torch.sum(torch.abs(visual_mean), dim=0)  # (d,)\n    \n    # Compute correlation between visual and textual features\n    correlation = torch.sum(visual_mean * clip_weights, dim=0)  # (d,)\n    \n    # Compute variance of category textual features\n    text_var = torch.var(clip_weights, dim=0)  # (d,)\n    \n    # Compute entropy of visual features\n    visual_prob = torch.softmax(visual_mean, dim=0)\n    entropy = -torch.sum(visual_prob * torch.log(visual_prob + 1e-10), dim=0)  # (d,)\n    \n    # Compute class-wise feature consistency\n    class_consistency = torch.mean(torch.var(train_feats, dim=1), dim=0)  # (d,)\n    \n    # Combine criteria\n    criterion = w0 * mi + (1 - w0) * inter_class_div - w1 * sparsity + (1 - w1) * text_var + correlation + entropy - class_consistency\n    \n    # Select topk features\n    _, indices = torch.topk(criterion, k=topk)\n    return indices",
          "objective": 40.14727,
          "other_inf": null
     }
]