[
     {
          "algorithm": "The new algorithm combines CLIP's zero-shot classifier logits, a feature importance-weighted GDA logits, a feature importance-weighted similarity logits between test features and class prototypes, a feature importance-weighted attention mechanism, and a feature importance-weighted cross-attention mechanism between test features and train features, with hyper-parameters controlling the contributions of each component, while introducing a feature importance-weighted normalization step for the train and test features, and additionally incorporates a feature importance-weighted similarity logits between test features and train features.",
          "code": "import torch\n\ndef compute_logits(train_feats, train_labels, test_feats, clip_weights, indices, alpha0, alpha1, alpha2):\n    num_classes, k, d = train_feats.shape\n    train_feats = train_feats.view(-1, d)\n    train_labels = train_labels.view(-1)\n    \n    # Normalize train and test features using only important channels\n    train_feats_norm = train_feats[:, indices] / torch.norm(train_feats[:, indices], dim=1, keepdim=True)\n    test_feats_norm = test_feats[:, indices] / torch.norm(test_feats[:, indices], dim=1, keepdim=True)\n    \n    # Compute per-class mean features using only important channels\n    mus = torch.cat([train_feats_norm[train_labels == i].mean(dim=0, keepdim=True) for i in range(num_classes)])\n    \n    # Estimate inverted covariance matrix using only important channels\n    center_vecs = torch.cat([train_feats_norm[train_labels == i] - mus[i].unsqueeze(0) for i in range(num_classes)])\n    cov_inv = center_vecs.shape[1] * torch.linalg.pinv((center_vecs.shape[0] - 1) * center_vecs.T.cov() + center_vecs.T.cov().trace() * torch.eye(center_vecs.shape[1]).cuda())\n    \n    # Compute GDA logits using only important channels\n    ps = torch.ones(num_classes).cuda() * 1. / num_classes\n    W = mus @ cov_inv\n    b = ps.log() - (W * mus).sum(dim=1) / 2\n    gda_logits = (test_feats_norm @ W.t() + b)\n    \n    # Compute CLIP logits\n    clip_logits = 100 * test_feats @ clip_weights.t()\n    \n    # Compute feature importance-weighted similarity logits between test features and class prototypes\n    prototype_logits = torch.cat([(test_feats_norm @ mus[i].unsqueeze(1)).mean(dim=1, keepdim=True) for i in range(num_classes)], dim=1)\n    \n    # Compute feature importance-weighted attention logits\n    channel_weights = torch.zeros(d).cuda()\n    channel_weights[indices] = alpha2\n    attention_logits = (test_feats * channel_weights) @ clip_weights.t()\n    \n    # Compute feature importance-weighted cross-attention logits\n    cross_attention_logits = torch.cat([(test_feats_norm @ train_feats_norm[train_labels == i].t()).mean(dim=1, keepdim=True) for i in range(num_classes)], dim=1)\n    \n    # Compute feature importance-weighted similarity logits between test features and train features\n    sim_logits = torch.cat([(test_feats_norm @ train_feats_norm[train_labels == i].t()).mean(dim=1, keepdim=True) for i in range(num_classes)], dim=1) * alpha1\n    \n    # Combine all logits with hyper-parameters\n    logits = clip_logits + alpha0 * gda_logits + alpha1 * prototype_logits + alpha2 * attention_logits + cross_attention_logits + sim_logits\n    \n    return logits",
          "objective": 39.50511,
          "other_inf": null
     },
     {
          "algorithm": "The new algorithm combines CLIP's zero-shot classifier logits, a feature importance-weighted GDA logits, a feature importance-weighted similarity logits between test features and train features, a feature importance-weighted attention mechanism, a feature importance-weighted cross-attention mechanism, a feature importance-weighted similarity logits between test features and class prototypes, and a feature importance-weighted feature fusion logits, while introducing a feature importance-weighted similarity logits between test features and class centroids and a feature importance-weighted similarity logits between test features and class means, with hyper-parameters controlling the contributions of each component.",
          "code": "import torch\n\ndef compute_logits(train_feats, train_labels, test_feats, clip_weights, indices, alpha0, alpha1, alpha2):\n    num_classes, k, d = train_feats.shape\n    train_feats = train_feats.view(-1, d)\n    train_labels = train_labels.view(-1)\n    \n    # Normalize train and test features using only important channels\n    train_feats_norm = train_feats[:, indices] / torch.norm(train_feats[:, indices], dim=1, keepdim=True)\n    test_feats_norm = test_feats[:, indices] / torch.norm(test_feats[:, indices], dim=1, keepdim=True)\n    \n    # Compute per-class mean features using only important channels\n    mus = torch.cat([train_feats_norm[train_labels == i].mean(dim=0, keepdim=True) for i in range(num_classes)])\n    \n    # Estimate inverted covariance matrix using only important channels\n    center_vecs = torch.cat([train_feats_norm[train_labels == i] - mus[i].unsqueeze(0) for i in range(num_classes)])\n    cov_inv = center_vecs.shape[1] * torch.linalg.pinv((center_vecs.shape[0] - 1) * center_vecs.T.cov() + center_vecs.T.cov().trace() * torch.eye(center_vecs.shape[1]).cuda())\n    \n    # Compute GDA logits using only important channels\n    ps = torch.ones(num_classes).cuda() * 1. / num_classes\n    W = mus @ cov_inv\n    b = ps.log() - (W * mus).sum(dim=1) / 2\n    gda_logits = (test_feats_norm @ W.t() + b)\n    \n    # Compute CLIP logits\n    clip_logits = 100 * test_feats @ clip_weights.t()\n    \n    # Compute importance-weighted similarity logits between test features and train features\n    weighted_test_feats = test_feats_norm * alpha1\n    weighted_train_feats = train_feats_norm * alpha1\n    sim_logits = torch.cat([(weighted_test_feats @ weighted_train_feats[train_labels == i].t()).mean(dim=1, keepdim=True) for i in range(num_classes)], dim=1)\n    \n    # Compute feature importance-weighted attention logits\n    channel_weights = torch.zeros(d).cuda()\n    channel_weights[indices] = alpha2\n    attention_logits = (test_feats * channel_weights) @ clip_weights.t()\n    \n    # Compute feature importance-weighted cross-attention logits\n    cross_attention_logits = torch.cat([(test_feats_norm @ train_feats_norm[train_labels == i].t()).mean(dim=1, keepdim=True) for i in range(num_classes)], dim=1)\n    \n    # Compute feature importance-weighted similarity logits between test features and class prototypes\n    prototype_logits = torch.cat([(test_feats_norm @ mus[i].unsqueeze(1)).mean(dim=1, keepdim=True) for i in range(num_classes)], dim=1)\n    \n    # Compute feature importance-weighted similarity logits between test features and class centroids\n    centroids = torch.cat([train_feats[train_labels == i].mean(dim=0, keepdim=True) for i in range(num_classes)])\n    centroid_logits = torch.cat([(test_feats @ centroids[i].unsqueeze(1)).mean(dim=1, keepdim=True) for i in range(num_classes)], dim=1)\n    \n    # Compute feature importance-weighted similarity logits between test features and class means\n    means = torch.cat([train_feats_norm[train_labels == i].mean(dim=0, keepdim=True) for i in range(num_classes)])\n    mean_logits = torch.cat([(test_feats_norm @ means[i].unsqueeze(1)).mean(dim=1, keepdim=True) for i in range(num_classes)], dim=1)\n    \n    # Compute feature importance-weighted feature fusion logits\n    fused_test_feats = test_feats_norm * alpha0\n    fused_clip_weights = clip_weights[:, indices] * alpha0\n    fusion_logits = (fused_test_feats @ fused_clip_weights.t())\n    \n    # Combine all logits with hyper-parameters\n    logits = clip_logits + alpha0 * gda_logits + alpha1 * sim_logits + alpha2 * attention_logits + alpha1 * cross_attention_logits + alpha1 * prototype_logits + alpha1 * centroid_logits + alpha1 * mean_logits + fusion_logits\n    \n    return logits",
          "objective": 39.50978,
          "other_inf": null
     },
     {
          "algorithm": "The new algorithm combines CLIP's zero-shot classifier logits, a feature importance-weighted GDA logits, a feature importance-weighted similarity logits between test features and class prototypes, a feature importance-weighted attention mechanism, and a feature importance-weighted contrastive logits between test features and train features, with hyper-parameters controlling the contributions of each component, while introducing a feature importance-weighted normalization step for the train and test features.",
          "code": "import torch\n\ndef compute_logits(train_feats, train_labels, test_feats, clip_weights, indices, alpha0, alpha1, alpha2):\n    num_classes, k, d = train_feats.shape\n    train_feats = train_feats.view(-1, d)\n    train_labels = train_labels.view(-1)\n    \n    # Normalize train and test features using only important channels\n    train_feats_norm = train_feats[:, indices] / torch.norm(train_feats[:, indices], dim=1, keepdim=True)\n    test_feats_norm = test_feats[:, indices] / torch.norm(test_feats[:, indices], dim=1, keepdim=True)\n    \n    # Compute per-class mean features using only important channels\n    mus = torch.cat([train_feats_norm[train_labels == i].mean(dim=0, keepdim=True) for i in range(num_classes)])\n    \n    # Estimate inverted covariance matrix using only important channels\n    center_vecs = torch.cat([train_feats_norm[train_labels == i] - mus[i].unsqueeze(0) for i in range(num_classes)])\n    cov_inv = center_vecs.shape[1] * torch.linalg.pinv((center_vecs.shape[0] - 1) * center_vecs.T.cov() + center_vecs.T.cov().trace() * torch.eye(center_vecs.shape[1]).cuda())\n    \n    # Compute GDA logits using only important channels\n    ps = torch.ones(num_classes).cuda() * 1. / num_classes\n    W = mus @ cov_inv\n    b = ps.log() - (W * mus).sum(dim=1) / 2\n    gda_logits = (test_feats_norm @ W.t() + b)\n    \n    # Compute CLIP logits\n    clip_logits = 100 * test_feats @ clip_weights.t()\n    \n    # Compute feature importance-weighted similarity logits between test features and class prototypes\n    prototype_logits = torch.cat([(test_feats_norm @ mus[i].unsqueeze(1)).mean(dim=1, keepdim=True) for i in range(num_classes)], dim=1)\n    \n    # Compute feature importance-weighted attention logits\n    channel_weights = torch.zeros(d).cuda()\n    channel_weights[indices] = alpha2\n    attention_logits = (test_feats * channel_weights) @ clip_weights.t()\n    \n    # Compute feature importance-weighted contrastive logits between test features and train features\n    contrastive_logits = torch.cat([(test_feats_norm @ train_feats_norm[train_labels == i].t()).mean(dim=1, keepdim=True) for i in range(num_classes)], dim=1) * alpha1\n    \n    # Combine all logits with hyper-parameters\n    logits = clip_logits + alpha0 * gda_logits + alpha1 * prototype_logits + alpha2 * attention_logits + contrastive_logits\n    \n    return logits",
          "objective": 39.5183,
          "other_inf": null
     },
     {
          "algorithm": "The new algorithm combines CLIP's zero-shot classifier logits, a feature importance-weighted GDA logits, a feature importance-weighted similarity logits between test features and class prototypes, a feature importance-weighted attention mechanism, and a feature importance-weighted contrastive logits between test features and train features, with hyper-parameters controlling the contributions of each component, while introducing a feature importance-weighted normalization step for the train and test features, and a feature importance-weighted aggregation of the logits components.",
          "code": "import torch\n\ndef compute_logits(train_feats, train_labels, test_feats, clip_weights, indices, alpha0, alpha1, alpha2):\n    num_classes, k, d = train_feats.shape\n    train_feats = train_feats.view(-1, d)\n    train_labels = train_labels.view(-1)\n    \n    # Normalize train and test features using only important channels\n    train_feats_norm = train_feats[:, indices] / torch.norm(train_feats[:, indices], dim=1, keepdim=True)\n    test_feats_norm = test_feats[:, indices] / torch.norm(test_feats[:, indices], dim=1, keepdim=True)\n    \n    # Compute per-class mean features using only important channels\n    mus = torch.cat([train_feats_norm[train_labels == i].mean(dim=0, keepdim=True) for i in range(num_classes)])\n    \n    # Estimate inverted covariance matrix using only important channels\n    center_vecs = torch.cat([train_feats_norm[train_labels == i] - mus[i].unsqueeze(0) for i in range(num_classes)])\n    cov_inv = center_vecs.shape[1] * torch.linalg.pinv((center_vecs.shape[0] - 1) * center_vecs.T.cov() + center_vecs.T.cov().trace() * torch.eye(center_vecs.shape[1]).cuda())\n    \n    # Compute GDA logits using only important channels\n    ps = torch.ones(num_classes).cuda() * 1. / num_classes\n    W = mus @ cov_inv\n    b = ps.log() - (W * mus).sum(dim=1) / 2\n    gda_logits = (test_feats_norm @ W.t() + b)\n    \n    # Compute CLIP logits\n    clip_logits = 100 * test_feats @ clip_weights.t()\n    \n    # Compute feature importance-weighted similarity logits between test features and class prototypes\n    prototype_logits = torch.cat([(test_feats_norm @ mus[i].unsqueeze(1)).mean(dim=1, keepdim=True) for i in range(num_classes)], dim=1)\n    \n    # Compute feature importance-weighted attention logits\n    channel_weights = torch.zeros(d).cuda()\n    channel_weights[indices] = alpha2\n    attention_logits = (test_feats * channel_weights) @ clip_weights.t()\n    \n    # Compute feature importance-weighted contrastive logits between test features and train features\n    contrastive_logits = torch.cat([(test_feats_norm @ train_feats_norm[train_labels == i].t()).mean(dim=1, keepdim=True) for i in range(num_classes)], dim=1) * alpha1\n    \n    # Combine all logits with hyper-parameters and feature importance-weighted aggregation\n    logits = (clip_logits + alpha0 * gda_logits + alpha1 * prototype_logits + alpha2 * attention_logits + contrastive_logits) * torch.tensor([1.0, alpha0, alpha1, alpha2, alpha1]).sum()\n    \n    return logits",
          "objective": 39.52946,
          "other_inf": null
     },
     {
          "algorithm": "The new algorithm combines CLIP's zero-shot classifier logits, a feature importance-weighted GDA logits, a feature importance-weighted similarity logits between test features and train features, a feature importance-weighted attention mechanism, a feature importance-weighted cross-attention mechanism, and a feature importance-weighted similarity logits between test features and class prototypes, with hyper-parameters controlling the contributions of each component, while introducing a feature importance-weighted normalization step for the train and test features, and additionally incorporates a feature importance-weighted cross-attention mechanism between test features and train features, and a feature importance-weighted similarity logits between test features and class prototypes, with an additional feature importance-weighted similarity logits between test features and class prototypes.",
          "code": "import torch\n\ndef compute_logits(train_feats, train_labels, test_feats, clip_weights, indices, alpha0, alpha1, alpha2):\n    num_classes, k, d = train_feats.shape\n    train_feats = train_feats.view(-1, d)\n    train_labels = train_labels.view(-1)\n    \n    # Normalize train and test features using only important channels\n    train_feats_norm = train_feats[:, indices] / torch.norm(train_feats[:, indices], dim=1, keepdim=True)\n    test_feats_norm = test_feats[:, indices] / torch.norm(test_feats[:, indices], dim=1, keepdim=True)\n    \n    # Compute per-class mean features using only important channels\n    mus = torch.cat([train_feats_norm[train_labels == i].mean(dim=0, keepdim=True) for i in range(num_classes)])\n    \n    # Estimate inverted covariance matrix using only important channels\n    center_vecs = torch.cat([train_feats_norm[train_labels == i] - mus[i].unsqueeze(0) for i in range(num_classes)])\n    cov_inv = center_vecs.shape[1] * torch.linalg.pinv((center_vecs.shape[0] - 1) * center_vecs.T.cov() + center_vecs.T.cov().trace() * torch.eye(center_vecs.shape[1]).cuda())\n    \n    # Compute GDA logits using only important channels\n    ps = torch.ones(num_classes).cuda() * 1. / num_classes\n    W = mus @ cov_inv\n    b = ps.log() - (W * mus).sum(dim=1) / 2\n    gda_logits = (test_feats_norm @ W.t() + b)\n    \n    # Compute CLIP logits\n    clip_logits = 100 * test_feats @ clip_weights.t()\n    \n    # Compute importance-weighted similarity logits between test features and train features\n    weighted_test_feats = test_feats_norm * alpha1\n    weighted_train_feats = train_feats_norm * alpha1\n    sim_logits = torch.cat([(weighted_test_feats @ weighted_train_feats[train_labels == i].t()).mean(dim=1, keepdim=True) for i in range(num_classes)], dim=1)\n    \n    # Compute feature importance-weighted attention logits\n    channel_weights = torch.zeros(d).cuda()\n    channel_weights[indices] = alpha2\n    attention_logits = (test_feats * channel_weights) @ clip_weights.t()\n    \n    # Compute feature importance-weighted cross-attention logits\n    cross_attention_logits = torch.cat([(test_feats_norm @ train_feats_norm[train_labels == i].t()).mean(dim=1, keepdim=True) for i in range(num_classes)], dim=1)\n    \n    # Compute feature importance-weighted similarity logits between test features and class prototypes\n    prototype_logits = torch.cat([(test_feats_norm @ mus[i].unsqueeze(1)).mean(dim=1, keepdim=True) for i in range(num_classes)], dim=1)\n    \n    # Compute feature importance-weighted similarity logits between test features and class prototypes\n    prototype_logits2 = torch.cat([(test_feats_norm @ mus[i].unsqueeze(1)).mean(dim=1, keepdim=True) for i in range(num_classes)], dim=1)\n    \n    # Combine all logits with hyper-parameters\n    logits = clip_logits + alpha0 * gda_logits + alpha1 * sim_logits + alpha2 * attention_logits + alpha1 * cross_attention_logits + alpha1 * prototype_logits + alpha1 * prototype_logits2\n    \n    return logits",
          "objective": 39.54727,
          "other_inf": null
     },
     {
          "algorithm": "The new algorithm combines CLIP's zero-shot classifier logits, a feature importance-weighted GDA logits, a feature importance-weighted similarity logits between test features and train features, a feature importance-weighted attention mechanism, a feature importance-weighted cross-attention mechanism, and a feature importance-weighted similarity logits between test features and class prototypes, while introducing a feature importance-weighted feature fusion logits and a feature importance-weighted similarity logits between test features and class centroids, with hyper-parameters controlling the contributions of each component.",
          "code": "import torch\n\ndef compute_logits(train_feats, train_labels, test_feats, clip_weights, indices, alpha0, alpha1, alpha2):\n    num_classes, k, d = train_feats.shape\n    train_feats = train_feats.view(-1, d)\n    train_labels = train_labels.view(-1)\n    \n    # Normalize train and test features using only important channels\n    train_feats_norm = train_feats[:, indices] / torch.norm(train_feats[:, indices], dim=1, keepdim=True)\n    test_feats_norm = test_feats[:, indices] / torch.norm(test_feats[:, indices], dim=1, keepdim=True)\n    \n    # Compute per-class mean features using only important channels\n    mus = torch.cat([train_feats_norm[train_labels == i].mean(dim=0, keepdim=True) for i in range(num_classes)])\n    \n    # Estimate inverted covariance matrix using only important channels\n    center_vecs = torch.cat([train_feats_norm[train_labels == i] - mus[i].unsqueeze(0) for i in range(num_classes)])\n    cov_inv = center_vecs.shape[1] * torch.linalg.pinv((center_vecs.shape[0] - 1) * center_vecs.T.cov() + center_vecs.T.cov().trace() * torch.eye(center_vecs.shape[1]).cuda())\n    \n    # Compute GDA logits using only important channels\n    ps = torch.ones(num_classes).cuda() * 1. / num_classes\n    W = mus @ cov_inv\n    b = ps.log() - (W * mus).sum(dim=1) / 2\n    gda_logits = (test_feats_norm @ W.t() + b)\n    \n    # Compute CLIP logits\n    clip_logits = 100 * test_feats @ clip_weights.t()\n    \n    # Compute importance-weighted similarity logits between test features and train features\n    weighted_test_feats = test_feats_norm * alpha1\n    weighted_train_feats = train_feats_norm * alpha1\n    sim_logits = torch.cat([(weighted_test_feats @ weighted_train_feats[train_labels == i].t()).mean(dim=1, keepdim=True) for i in range(num_classes)], dim=1)\n    \n    # Compute feature importance-weighted attention logits\n    channel_weights = torch.zeros(d).cuda()\n    channel_weights[indices] = alpha2\n    attention_logits = (test_feats * channel_weights) @ clip_weights.t()\n    \n    # Compute feature importance-weighted cross-attention logits\n    cross_attention_logits = torch.cat([(test_feats_norm @ train_feats_norm[train_labels == i].t()).mean(dim=1, keepdim=True) for i in range(num_classes)], dim=1)\n    \n    # Compute feature importance-weighted similarity logits between test features and class prototypes\n    prototype_logits = torch.cat([(test_feats_norm @ mus[i].unsqueeze(1)).mean(dim=1, keepdim=True) for i in range(num_classes)], dim=1)\n    \n    # Compute feature importance-weighted similarity logits between test features and class centroids\n    centroids = torch.cat([train_feats[train_labels == i].mean(dim=0, keepdim=True) for i in range(num_classes)])\n    centroid_logits = torch.cat([(test_feats @ centroids[i].unsqueeze(1)).mean(dim=1, keepdim=True) for i in range(num_classes)], dim=1)\n    \n    # Compute feature importance-weighted feature fusion logits\n    fused_test_feats = test_feats_norm * alpha0\n    fused_clip_weights = clip_weights[:, indices] * alpha0\n    fusion_logits = (fused_test_feats @ fused_clip_weights.t())\n    \n    # Combine all logits with hyper-parameters\n    logits = clip_logits + alpha0 * gda_logits + alpha1 * sim_logits + alpha2 * attention_logits + alpha1 * cross_attention_logits + alpha1 * prototype_logits + alpha1 * centroid_logits + fusion_logits\n    \n    return logits",
          "objective": 39.55153,
          "other_inf": null
     },
     {
          "algorithm": "The new algorithm combines CLIP's zero-shot classifier logits, a feature importance-weighted GDA logits, a feature importance-weighted similarity logits between test features and class prototypes, a feature importance-weighted attention mechanism, and a feature importance-weighted contrastive logits between test features and train features, with hyper-parameters controlling the contributions of each component, while introducing a feature importance-weighted normalization step for the train and test features, and additionally incorporates a feature importance-weighted similarity logits between test features and class centroids, and a feature importance-weighted similarity logits between test features and class means.",
          "code": "import torch\n\ndef compute_logits(train_feats, train_labels, test_feats, clip_weights, indices, alpha0, alpha1, alpha2):\n    num_classes, k, d = train_feats.shape\n    train_feats = train_feats.view(-1, d)\n    train_labels = train_labels.view(-1)\n    \n    # Normalize train and test features using only important channels\n    train_feats_norm = train_feats[:, indices] / torch.norm(train_feats[:, indices], dim=1, keepdim=True)\n    test_feats_norm = test_feats[:, indices] / torch.norm(test_feats[:, indices], dim=1, keepdim=True)\n    \n    # Compute per-class mean features using only important channels\n    mus = torch.cat([train_feats_norm[train_labels == i].mean(dim=0, keepdim=True) for i in range(num_classes)])\n    \n    # Estimate inverted covariance matrix using only important channels\n    center_vecs = torch.cat([train_feats_norm[train_labels == i] - mus[i].unsqueeze(0) for i in range(num_classes)])\n    cov_inv = center_vecs.shape[1] * torch.linalg.pinv((center_vecs.shape[0] - 1) * center_vecs.T.cov() + center_vecs.T.cov().trace() * torch.eye(center_vecs.shape[1]).cuda())\n    \n    # Compute GDA logits using only important channels\n    ps = torch.ones(num_classes).cuda() * 1. / num_classes\n    W = mus @ cov_inv\n    b = ps.log() - (W * mus).sum(dim=1) / 2\n    gda_logits = (test_feats_norm @ W.t() + b)\n    \n    # Compute CLIP logits\n    clip_logits = 100 * test_feats @ clip_weights.t()\n    \n    # Compute feature importance-weighted similarity logits between test features and class prototypes\n    prototype_logits = torch.cat([(test_feats_norm @ mus[i].unsqueeze(1)).mean(dim=1, keepdim=True) for i in range(num_classes)], dim=1)\n    \n    # Compute feature importance-weighted attention logits\n    channel_weights = torch.zeros(d).cuda()\n    channel_weights[indices] = alpha2\n    attention_logits = (test_feats * channel_weights) @ clip_weights.t()\n    \n    # Compute feature importance-weighted contrastive logits between test features and train features\n    contrastive_logits = torch.cat([(test_feats_norm @ train_feats_norm[train_labels == i].t()).mean(dim=1, keepdim=True) for i in range(num_classes)], dim=1) * alpha1\n    \n    # Compute feature importance-weighted similarity logits between test features and class centroids\n    centroids = torch.cat([train_feats[train_labels == i].mean(dim=0, keepdim=True) for i in range(num_classes)])\n    centroid_logits = torch.cat([(test_feats @ centroids[i].unsqueeze(1)).mean(dim=1, keepdim=True) for i in range(num_classes)], dim=1)\n    \n    # Compute feature importance-weighted similarity logits between test features and class means\n    means = torch.cat([train_feats_norm[train_labels == i].mean(dim=0, keepdim=True) for i in range(num_classes)])\n    mean_logits = torch.cat([(test_feats_norm @ means[i].unsqueeze(1)).mean(dim=1, keepdim=True) for i in range(num_classes)], dim=1)\n    \n    # Combine all logits with hyper-parameters\n    logits = clip_logits + alpha0 * gda_logits + alpha1 * prototype_logits + alpha2 * attention_logits + alpha1 * contrastive_logits + alpha1 * centroid_logits + alpha1 * mean_logits\n    \n    return logits",
          "objective": 39.55278,
          "other_inf": null
     },
     {
          "algorithm": "The new algorithm combines CLIP's zero-shot classifier logits, a feature importance-weighted GDA logits, a feature importance-weighted similarity logits between test features and train features, a feature importance-weighted attention mechanism, and a feature importance-weighted class prototype similarity logits, while introducing a novel feature importance-weighted cross-attention mechanism between test features and train features, and additionally incorporates a feature importance-weighted normalization step for the train and test features.",
          "code": "import torch\n\ndef compute_logits(train_feats, train_labels, test_feats, clip_weights, indices, alpha0, alpha1, alpha2):\n    num_classes, k, d = train_feats.shape\n    train_feats = train_feats.view(-1, d)\n    train_labels = train_labels.view(-1)\n    \n    # Normalize train and test features using only important channels\n    train_feats_norm = train_feats[:, indices] / torch.norm(train_feats[:, indices], dim=1, keepdim=True)\n    test_feats_norm = test_feats[:, indices] / torch.norm(test_feats[:, indices], dim=1, keepdim=True)\n    \n    # Compute per-class mean features using only important channels\n    mus = torch.cat([train_feats_norm[train_labels == i].mean(dim=0, keepdim=True) for i in range(num_classes)])\n    \n    # Estimate inverted covariance matrix using only important channels\n    center_vecs = torch.cat([train_feats_norm[train_labels == i] - mus[i].unsqueeze(0) for i in range(num_classes)])\n    cov_inv = center_vecs.shape[1] * torch.linalg.pinv((center_vecs.shape[0] - 1) * center_vecs.T.cov() + center_vecs.T.cov().trace() * torch.eye(center_vecs.shape[1]).cuda())\n    \n    # Compute GDA logits using only important channels\n    ps = torch.ones(num_classes).cuda() * 1. / num_classes\n    W = mus @ cov_inv\n    b = ps.log() - (W * mus).sum(dim=1) / 2\n    gda_logits = (test_feats_norm @ W.t() + b)\n    \n    # Compute CLIP logits\n    clip_logits = 100 * test_feats @ clip_weights.t()\n    \n    # Compute importance-weighted similarity logits between test features and train features\n    weighted_test_feats = test_feats_norm * alpha1\n    weighted_train_feats = train_feats_norm * alpha1\n    sim_logits = torch.cat([(weighted_test_feats @ weighted_train_feats[train_labels == i].t()).mean(dim=1, keepdim=True) for i in range(num_classes)], dim=1)\n    \n    # Compute feature importance-weighted attention logits\n    channel_weights = torch.zeros(d).cuda()\n    channel_weights[indices] = alpha2\n    attention_logits = (test_feats * channel_weights) @ clip_weights.t()\n    \n    # Compute feature importance-weighted cross-attention logits\n    cross_attention_logits = torch.cat([(test_feats_norm @ train_feats_norm[train_labels == i].t()).mean(dim=1, keepdim=True) for i in range(num_classes)], dim=1)\n    \n    # Compute feature importance-weighted class prototype similarity logits\n    prototype_sim_logits = (test_feats_norm @ mus.t()) * alpha1\n    \n    # Combine all logits with hyper-parameters\n    logits = clip_logits + alpha0 * gda_logits + alpha1 * sim_logits + alpha2 * attention_logits + alpha1 * cross_attention_logits + alpha1 * prototype_sim_logits\n    \n    return logits",
          "objective": 39.55308,
          "other_inf": null
     },
     {
          "algorithm": "The new algorithm combines CLIP's zero-shot classifier logits, a feature importance-weighted GDA logits, a feature importance-weighted similarity logits between test features and train features, a feature importance-weighted attention mechanism, a feature importance-weighted feature fusion logits, and a feature importance-weighted cross-attention mechanism between test features and train features, while introducing a feature importance-weighted similarity logits between test features and class prototypes and a feature importance-weighted similarity logits between test features and class centroids, with hyper-parameters controlling the contributions of each component.",
          "code": "import torch\n\ndef compute_logits(train_feats, train_labels, test_feats, clip_weights, indices, alpha0, alpha1, alpha2):\n    num_classes, k, d = train_feats.shape\n    train_feats = train_feats.view(-1, d)\n    train_labels = train_labels.view(-1)\n    \n    # Normalize train and test features using only important channels\n    train_feats_norm = train_feats[:, indices] / torch.norm(train_feats[:, indices], dim=1, keepdim=True)\n    test_feats_norm = test_feats[:, indices] / torch.norm(test_feats[:, indices], dim=1, keepdim=True)\n    \n    # Compute per-class mean features using only important channels\n    mus = torch.cat([train_feats_norm[train_labels == i].mean(dim=0, keepdim=True) for i in range(num_classes)])\n    \n    # Estimate inverted covariance matrix using only important channels\n    center_vecs = torch.cat([train_feats_norm[train_labels == i] - mus[i].unsqueeze(0) for i in range(num_classes)])\n    cov_inv = center_vecs.shape[1] * torch.linalg.pinv((center_vecs.shape[0] - 1) * center_vecs.T.cov() + center_vecs.T.cov().trace() * torch.eye(center_vecs.shape[1]).cuda())\n    \n    # Compute GDA logits using only important channels\n    ps = torch.ones(num_classes).cuda() * 1. / num_classes\n    W = mus @ cov_inv\n    b = ps.log() - (W * mus).sum(dim=1) / 2\n    gda_logits = (test_feats_norm @ W.t() + b)\n    \n    # Compute CLIP logits\n    clip_logits = 100 * test_feats @ clip_weights.t()\n    \n    # Compute importance-weighted similarity logits between test features and train features\n    weighted_test_feats = test_feats_norm * alpha1\n    weighted_train_feats = train_feats_norm * alpha1\n    sim_logits = torch.cat([(weighted_test_feats @ weighted_train_feats[train_labels == i].t()).mean(dim=1, keepdim=True) for i in range(num_classes)], dim=1)\n    \n    # Compute feature importance-weighted attention logits\n    channel_weights = torch.zeros(d).cuda()\n    channel_weights[indices] = alpha2\n    attention_logits = (test_feats * channel_weights) @ clip_weights.t()\n    \n    # Compute feature importance-weighted feature fusion logits\n    fused_test_feats = test_feats_norm * alpha0\n    fused_clip_weights = clip_weights[:, indices] * alpha0\n    fusion_logits = (fused_test_feats @ fused_clip_weights.t())\n    \n    # Compute feature importance-weighted cross-attention logits\n    cross_attention_logits = torch.cat([(test_feats_norm @ train_feats_norm[train_labels == i].t()).mean(dim=1, keepdim=True) for i in range(num_classes)], dim=1)\n    \n    # Compute feature importance-weighted similarity logits between test features and class prototypes\n    prototype_logits = torch.cat([(test_feats_norm @ mus[i].unsqueeze(1)).mean(dim=1, keepdim=True) for i in range(num_classes)], dim=1)\n    \n    # Compute feature importance-weighted similarity logits between test features and class centroids\n    centroids = torch.cat([train_feats[train_labels == i].mean(dim=0, keepdim=True) for i in range(num_classes)])\n    centroid_logits = torch.cat([(test_feats @ centroids[i].unsqueeze(1)).mean(dim=1, keepdim=True) for i in range(num_classes)], dim=1)\n    \n    # Combine all logits with hyper-parameters\n    logits = clip_logits + alpha0 * gda_logits + alpha1 * sim_logits + alpha2 * attention_logits + fusion_logits + alpha1 * cross_attention_logits + alpha1 * prototype_logits + alpha1 * centroid_logits\n    \n    return logits",
          "objective": 39.55486,
          "other_inf": null
     },
     {
          "algorithm": "The new algorithm combines CLIP's zero-shot classifier logits, a feature importance-weighted GDA logits, a feature importance-weighted similarity logits between test features and train features, a feature importance-weighted attention mechanism, and a feature importance-weighted cross-attention mechanism, with hyper-parameters controlling the contributions of each component, while introducing a feature importance-weighted normalization step for the train and test features, and additionally incorporates a feature importance-weighted cross-attention mechanism between test features and train features, and a feature importance-weighted similarity logits between test features and class prototypes.",
          "code": "import torch\n\ndef compute_logits(train_feats, train_labels, test_feats, clip_weights, indices, alpha0, alpha1, alpha2):\n    num_classes, k, d = train_feats.shape\n    train_feats = train_feats.view(-1, d)\n    train_labels = train_labels.view(-1)\n    \n    # Normalize train and test features using only important channels\n    train_feats_norm = train_feats[:, indices] / torch.norm(train_feats[:, indices], dim=1, keepdim=True)\n    test_feats_norm = test_feats[:, indices] / torch.norm(test_feats[:, indices], dim=1, keepdim=True)\n    \n    # Compute per-class mean features using only important channels\n    mus = torch.cat([train_feats_norm[train_labels == i].mean(dim=0, keepdim=True) for i in range(num_classes)])\n    \n    # Estimate inverted covariance matrix using only important channels\n    center_vecs = torch.cat([train_feats_norm[train_labels == i] - mus[i].unsqueeze(0) for i in range(num_classes)])\n    cov_inv = center_vecs.shape[1] * torch.linalg.pinv((center_vecs.shape[0] - 1) * center_vecs.T.cov() + center_vecs.T.cov().trace() * torch.eye(center_vecs.shape[1]).cuda())\n    \n    # Compute GDA logits using only important channels\n    ps = torch.ones(num_classes).cuda() * 1. / num_classes\n    W = mus @ cov_inv\n    b = ps.log() - (W * mus).sum(dim=1) / 2\n    gda_logits = (test_feats_norm @ W.t() + b)\n    \n    # Compute CLIP logits\n    clip_logits = 100 * test_feats @ clip_weights.t()\n    \n    # Compute importance-weighted similarity logits between test features and train features\n    weighted_test_feats = test_feats_norm * alpha1\n    weighted_train_feats = train_feats_norm * alpha1\n    sim_logits = torch.cat([(weighted_test_feats @ weighted_train_feats[train_labels == i].t()).mean(dim=1, keepdim=True) for i in range(num_classes)], dim=1)\n    \n    # Compute feature importance-weighted attention logits\n    channel_weights = torch.zeros(d).cuda()\n    channel_weights[indices] = alpha2\n    attention_logits = (test_feats * channel_weights) @ clip_weights.t()\n    \n    # Compute feature importance-weighted cross-attention logits\n    cross_attention_logits = torch.cat([(test_feats_norm @ train_feats_norm[train_labels == i].t()).mean(dim=1, keepdim=True) for i in range(num_classes)], dim=1)\n    \n    # Compute feature importance-weighted similarity logits between test features and class prototypes\n    prototype_logits = torch.cat([(test_feats_norm @ mus[i].unsqueeze(1)).mean(dim=1, keepdim=True) for i in range(num_classes)], dim=1)\n    \n    # Combine all logits with hyper-parameters\n    logits = clip_logits + alpha0 * gda_logits + alpha1 * sim_logits + alpha2 * attention_logits + alpha1 * cross_attention_logits + alpha1 * prototype_logits\n    \n    return logits",
          "objective": 39.55525,
          "other_inf": null
     }
]