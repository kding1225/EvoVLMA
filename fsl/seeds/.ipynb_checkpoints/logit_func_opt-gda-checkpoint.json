[
     {
          "algorithm": "The logits consist of two parts: the logits computed by CLIP's zero-shot classifier and the logits computed by Gaussian Discriminant Analysis (GDA) model. In each part, all feature channels are used. GDA is a probabilistic generative model for classification that assumes all classes are generated by Gaussian distributions with a common covariance matrix but different mean vectors. GDA first computes per-class mean vector and then estimates the inverted covariance matrix. After that the weight and bias of the GDA classifier can be computed.",
          "code": "import torch\n\ndef compute_logits(train_feats, train_labels, test_feats, clip_weights, indices, alpha0, alpha1, alpha2):\n\n    num_classes, k, d = train_feats.shape\n    train_feats = train_feats.view(-1, d)\n    train_labels = train_labels.view(-1)\n    \n    # compute per-class mean features\n    mus = torch.cat([train_feats[train_labels == i].mean(dim=0, keepdim=True) for i in range(num_classes)])\n\n    # use KS Estimator to estimate inverted covariance matrix\n    center_vecs = torch.cat([train_feats[train_labels == i] - mus[i].unsqueeze(0) for i in range(num_classes)])\n    cov_inv = center_vecs.shape[1] * torch.linalg.pinv((center_vecs.shape[0] - 1) * center_vecs.T.cov() + center_vecs.T.cov().trace() * torch.eye(center_vecs.shape[1]).cuda())     \n\n    ps = torch.ones(num_classes).cuda() * 1. / num_classes\n    W = mus @ cov_inv\n    b = ps.log() - (W*mus).sum(dim=1) / 2\n    gda_logits = (test_feats @ W.t() + b)\n\n    clip_logits = 100*test_feats @ clip_weights.t() \n    logits = clip_logits + alpha0 * gda_logits\n    \n    return logits",
          "objective": 10000.0,
          "other_inf": null
     }
]