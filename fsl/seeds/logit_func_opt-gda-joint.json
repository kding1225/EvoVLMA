[
     {
          "algorithm": "The algorithm has two steps. First, select important feature channels according to a devised criterion. The criterion gives high scores for channels that minimize the inter-class similarity of the concatenated features of visual and category textual features, but maximize the variance of category textual features. Second, compute logits by combining the logits generated by CLIP's zero-shot classifier and the logits computed by Gaussian Discriminant Analysis (GDA) model. In each part, all feature channels instead of selected channels are used. GDA is a probabilistic generative model for classification that assumes all classes are generated by Gaussian distributions with a common covariance matrix but different mean vectors. GDA first computes per-class mean vector and then estimates the inverted covariance matrix. After that the weight and bias of the GDA classifier can be computed.",
          "code": "import torch\nimport torch.nn.functional as F\n\ndef feat_selection(clip_weights, train_feats, w0, w1, topk):\n    # feature selection\n    feats = torch.cat([clip_weights.unsqueeze(1), train_feats], dim=1)\n    cate_num, samp_num, feat_dim = feats.shape\n    sim_sum = torch.zeros((feat_dim)).cuda()\n    count = 0\n    for i in range(cate_num):\n        for j in range(cate_num):\n            if i != j:\n                sim_sum += (feats[i].unsqueeze(1) * feats[j].unsqueeze(0)).mean(dim=0).mean(dim=0)\n                count += samp_num*samp_num\n    sim = sim_sum / count\n    criterion = (-1) * w0 * sim + w1 * torch.var(clip_weights, dim=0)\n    _, indices = torch.topk(criterion, k=topk)\n    return indices\n\ndef compute_logits_with_fs(train_feats, train_labels, test_feats, clip_weights, indices, alpha0, alpha1, alpha2):\n\n    cate_num, samp_num, feat_dim = train_feats.shape\n    train_feats = train_feats.view(-1, feat_dim)\n    train_labels = train_labels.view(-1)\n    \n    # compute per-class mean features\n    mus = torch.cat([train_feats[train_labels == i].mean(dim=0, keepdim=True) for i in range(cate_num)])\n\n    # use KS Estimator to estimate inverted covariance matrix\n    center_vecs = torch.cat([train_feats[train_labels == i] - mus[i].unsqueeze(0) for i in range(cate_num)])\n    cov_inv = center_vecs.shape[1] * torch.linalg.pinv((center_vecs.shape[0] - 1) * center_vecs.T.cov() + center_vecs.T.cov().trace() * torch.eye(center_vecs.shape[1]).cuda())     \n\n    ps = torch.ones(cate_num).cuda() * 1. / cate_num\n    W = mus @ cov_inv\n    b = ps.log() - (W*mus).sum(dim=1) / 2\n    gda_logits = (test_feats @ W.t() + b)\n\n    clip_logits = 100*test_feats @ clip_weights.t() \n    logits = clip_logits + alpha0 * gda_logits\n    \n    return logits\n\ndef compute_logits(train_feats, train_labels, test_feats, clip_weights, w0, w1, topk, alpha0, alpha1, alpha2):\n\n    # feature selection\n    indices = feat_selection(clip_weights, train_feats, w0, w1, topk)\n    \n    # compute logits\n    logits = compute_logits_with_fs(train_feats, train_labels, test_feats, clip_weights, indices, alpha0, alpha1, alpha2)\n    \n    return logits",
          "objective": 10000.0,
          "other_inf": null
     }
]